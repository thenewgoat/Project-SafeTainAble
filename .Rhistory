long_data <- accident %>%
select(RECOVERED_BBLS_category, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(RECOVERED_BBLS_category))
avg_data <- long_data %>%
group_by(RECOVERED_BBLS_category, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = RECOVERED_BBLS_category, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "fill") +
labs(x = "Unintentional Release", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type and Recovered Commodity") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels)
long_data <- accident %>%
select(COMMODITY_REACHED_HCA, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(COMMODITY_REACHED_HCA))
avg_data <- long_data %>%
group_by(COMMODITY_REACHED_HCA, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = COMMODITY_REACHED_HCA, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "COMMODITY_REACHED_HCA", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type and COMMODITY_REACHED_HCA") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels)
long_data <- accident %>%
select(COMMODITY_REACHED_HCA, CAUSE, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(COMMODITY_REACHED_HCA, CAUSE))
avg_data <- long_data %>%
group_by(COMMODITY_REACHED_HCA, CAUSE, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = COMMODITY_REACHED_HCA, y = Avg_Cost, fill = CAUSE)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "COMMODITY_REACHED_HCA", y = "Average Cost", fill = "Cause") +
ggtitle("Average Cost against Cost Type and COMMODITY_REACHED_HCA") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15))
long_data <- accident %>%
select(COULD_BE_HCA, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(COULD_BE_HCA))
avg_data <- long_data %>%
group_by(COULD_BE_HCA, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = COULD_BE_HCA, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "COULD_BE_HCA", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type and COULD_BE_HCA") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels)
long_data <- accident %>%
select(`CAUSE`, REMEDIATION_IND, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(`CAUSE`, REMEDIATION_IND))
avg_data <- long_data %>%
group_by(`CAUSE`, REMEDIATION_IND, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = CAUSE, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "Cause", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type, Cause and Remediation Indicator") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels) +
theme(axis.text.x = element_text(size=7, angle = 90)) +
facet_grid(.~ REMEDIATION_IND)
long_data <- accident %>%
select(`CAUSE`, VEGETATION_REMED_IND, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(`CAUSE`, VEGETATION_REMED_IND))
avg_data <- long_data %>%
group_by(`CAUSE`, VEGETATION_REMED_IND, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = CAUSE, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "Cause", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type, Cause and Vegetation Remediation Indicator") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels) +
theme(axis.text.x = element_text(size=7, angle = 90)) +
facet_grid(.~ VEGETATION_REMED_IND)
long_data <- accident %>%
select(`CAUSE`, GROUNDWATER_REMED_IND, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(`CAUSE`, GROUNDWATER_REMED_IND))
avg_data <- long_data %>%
group_by(`CAUSE`, GROUNDWATER_REMED_IND, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = CAUSE, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "Cause", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type, Cause and Groundwater Remediation Indicator") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels) +
theme(axis.text.x = element_text(size=7, angle = 90)) +
facet_grid(.~ GROUNDWATER_REMED_IND)
long_data <- accident %>%
select(`CAUSE`, LONG_TERM_ASSESSMENT, starts_with("EST_COST", )) %>%
gather(key = "Cost_Type", value = "Cost", -c(`CAUSE`, LONG_TERM_ASSESSMENT))
avg_data <- long_data %>%
group_by(`CAUSE`, LONG_TERM_ASSESSMENT, Cost_Type) %>%
summarise(Avg_Cost = mean(Cost, na.rm = TRUE))
ggplot(avg_data, aes(x = CAUSE, y = Avg_Cost, fill = Cost_Type)) +
geom_bar(stat = "identity", position = "stack") +
labs(x = "Cause", y = "Average Cost", fill = "Cost Type") +
ggtitle("Average Cost against Cost Type, Cause and Long Term Assessment") +
scale_x_discrete(labels = function(x) str_wrap(x, width = 15)) +
scale_fill_discrete(labels = labels) +
theme(axis.text.x = element_text(size=7, angle = 90)) +
facet_grid(.~ LONG_TERM_ASSESSMENT)
##-----------------------Train-Test Split---------------------------------------
# createDataPartition() is used because some levels of SYSTEM_PART_INVOLVED have very few or even single observation and
# we have to make sure all levels are split into both train and testset.
set.seed(1)
train.index <- createDataPartition(accident$SYSTEM_PART_INVOLVED, p = 0.7, list = FALSE)
trainset <- accident[ train.index,]
testset  <- accident[-train.index,]
dim(trainset) #2712 rows
dim(testset) #1158 rows
#Step 0: to get some initial insights from full model, i.e., with all relevant X variables
m.full <- lm(TOTAL_COST ~ IYEAR+ON_OFF_SHORE+LOCATION_LATITUDE+LOCATION_LONGITUDE+LOCATION_TYPE+INCIDENT_AREA_TYPE+
INCIDENT_AREA_SUBTYPE+SYSTEM_PART_INVOLVED+CAUSE+COMMODITY_RELEASED_TYPE+COMMODITY_SUBTYPE+
UNINTENTIONAL_RELEASE_BBLS+INTENTIONAL_RELEASE_BBLS+RECOVERED_BBLS+RELEASE_TYPE+IGNITE_IND+EXPLODE_IND+
SHUTDOWN_DUE_ACCIDENT_IND+NUM_PUB_EVACUATED+INJURY_IND+NUM_EMP_INJURIES+NUM_CONTR_INJURIES+NUM_WORKER_INJURIES+
NUM_GP_INJURIES+INJURE+FATALITY_IND+NUM_EMP_FATALITIES+NUM_CONTR_FATALITIES+NUM_WORKER_FATALITIES+NUM_GP_FATALITIES+
FATAL+WILDLIFE_IMPACT_IND+FISH_AQUATIC_IMPACT_IND+TERRESTRIAL_IMPACT_IND+SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+
REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+SOIL_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+
WATER_CONTAM_IND+OCEAN_SEAWATER_IND+SURFACE_CONTAM_IND+GROUNDWATER_CONTAM_IND+COMMODITY_REACHED_HCA+response_delay,
data = trainset)
summary(m.full)
#Step 1: Select variables based on p-value, i.e., lower than 5%
m1 <- lm(TOTAL_COST ~
ON_OFF_SHORE+
LOCATION_LONGITUDE+
LOCATION_TYPE+
INCIDENT_AREA_SUBTYPE+
SYSTEM_PART_INVOLVED+
CAUSE+
UNINTENTIONAL_RELEASE_BBLS+
INTENTIONAL_RELEASE_BBLS +
RECOVERED_BBLS+
RELEASE_TYPE+
IGNITE_IND+
SHUTDOWN_DUE_ACCIDENT_IND+
FATALITY_IND+
NUM_CONTR_FATALITIES+
WILDLIFE_IMPACT_IND+
FISH_AQUATIC_IMPACT_IND+
LONG_TERM_ASSESSMENT+
SURFACE_WATER_REMED_IND+
GROUNDWATER_REMED_IND+
VEGETATION_REMED_IND+
WATER_CONTAM_IND+
SURFACE_CONTAM_IND+
COMMODITY_REACHED_HCA+
response_delay
,data = trainset)
summary(m1)
#Step 2: Further elimination of variables using Automatic Selection Algorithm
##2.1 Stepwise AIC Regression
ols_step_both_aic(m1, details = TRUE)  #response_delay and ON_OFF_SHORE are removed
##2.2 Backward Elimination
m_back <- step(m1)
summary(m_back) #Similarly, response_delay and ON_OFF_SHORE are removed
#Step 3: Removing variable that has no practical significant, i.e., not applicable to Aramco
#LOCATION_LONGITUDE is removed because this geographical information is for pipelines in the US
m2 <- lm(TOTAL_COST ~
INCIDENT_AREA_SUBTYPE+
UNINTENTIONAL_RELEASE_BBLS+
INTENTIONAL_RELEASE_BBLS+
RECOVERED_BBLS+
CAUSE+
LONG_TERM_ASSESSMENT+
SYSTEM_PART_INVOLVED+
VEGETATION_REMED_IND+
COMMODITY_REACHED_HCA+
WILDLIFE_IMPACT_IND+
LOCATION_TYPE+
GROUNDWATER_REMED_IND+
FATALITY_IND+
RELEASE_TYPE+
SHUTDOWN_DUE_ACCIDENT_IND+
NUM_CONTR_FATALITIES+
SURFACE_WATER_REMED_IND+
SURFACE_CONTAM_IND+
WATER_CONTAM_IND+
FISH_AQUATIC_IMPACT_IND+
IGNITE_IND
,data = trainset)
summary(m2)
#Step 4: Remove statistically insignificant variables based on p-value again
#IGNITE_IND is removed
m3 <- lm(TOTAL_COST ~
SYSTEM_PART_INVOLVED+
CAUSE+
COMMODITY_RELEASED_TYPE+
UNINTENTIONAL_RELEASE_BBLS +
INTENTIONAL_RELEASE_BBLS+
RECOVERED_BBLS +
RELEASE_TYPE+
SHUTDOWN_DUE_ACCIDENT_IND+
NUM_CONTR_FATALITIES+
FATALITY_IND+
WILDLIFE_IMPACT_IND+
FISH_AQUATIC_IMPACT_IND+
LONG_TERM_ASSESSMENT+
SURFACE_WATER_REMED_IND+
GROUNDWATER_REMED_IND+
VEGETATION_REMED_IND+
WATER_CONTAM_IND+
SURFACE_CONTAM_IND+
COMMODITY_REACHED_HCA
,data = trainset)
summary(m3)
#Step 5: Check VIF to detect multicollinearity and redundancy in our model
#No multicollinearity -> VIF (continuous Xs) <10 / adj-GVIF(categorical Xs) <2
vif(m3)
# Based on domain knowledge and our investigation:
# WILDLIFE_IMPACT_IND and FISH_AQUATIC_IMPACT_IND are correlated
table(WILDLIFE_IMPACT_IND=accident$WILDLIFE_IMPACT_IND,FISH_AQUATIC_IMPACT_IND=accident$FISH_AQUATIC_IMPACT_IND)
mean(accident$WILDLIFE_IMPACT_IND==accident$FISH_AQUATIC_IMPACT_IND) #percentage of agreement: 0.9997416
# WATER_CONTAM_IND and SURFACE_CONTAM_IND are correalted.
table(WATER_CONTAM_IND=accident$WATER_CONTAM_IND,SURFACE_CONTAM_IND=accident$SURFACE_CONTAM_IND)
mean(accident$WATER_CONTAM_IND==accident$SURFACE_CONTAM_IND) #percentage of agreement: 0.9868217
# FISH_AQUATIC_IMPACT_IND and WATER_CONTAM_IND are removed due to their higher p-value, suggesting
# smaller predictive power as compared to WILDLIFE_IMPACT_IND and SURFACE_CONTAM_IND respectively
m4 <- lm(TOTAL_COST ~
SYSTEM_PART_INVOLVED+
CAUSE+
COMMODITY_RELEASED_TYPE+
UNINTENTIONAL_RELEASE_BBLS +
INTENTIONAL_RELEASE_BBLS+
RECOVERED_BBLS +
RELEASE_TYPE+
SHUTDOWN_DUE_ACCIDENT_IND+
NUM_CONTR_FATALITIES+
FATALITY_IND+
WILDLIFE_IMPACT_IND+
LONG_TERM_ASSESSMENT+
SURFACE_WATER_REMED_IND+
GROUNDWATER_REMED_IND+
VEGETATION_REMED_IND+
SURFACE_CONTAM_IND+
COMMODITY_REACHED_HCA
,data = trainset)
vif(m4) #No more multicollinearity issue
summary(m4) #Multiple R-squared:  0.4625,	Adjusted R-squared:  0.4557
#Step 6: Compute trainset and testset errors
# Residuals = Error = Actual TOTAL_COST - Model Predicted TOTAL_COST
# Trainset Errors
RMSE.m4.train <- sqrt(mean(residuals(m4)^2))
# Testset Errors
predict.m4.test <- predict(m4, newdata = testset)
testset.error <- testset$TOTAL_COST - predict.m4.test
RMSE.m4.test <- sqrt(mean(testset.error^2))
RMSE.m4.train #148406.4
RMSE.m4.test #151716.3
#Step 7: Diagnostic Checks
par(mfrow = c(2,2))
plot(m4)  # Plot model 4 diagnostics
par(mfrow = c(1,1))
#The CART algorithm works to find the independent variables that create the best homogeneous group when splitting the data.
#Thus, there is no need to specify important independent variable and CART will handle it automatically
set.seed(2406) #for 10-fold CV
#Step 1: Grow Tree to max by including all relevant variables and set cp to 0
cart1 <- rpart(TOTAL_COST ~ IYEAR+ON_OFF_SHORE+LOCATION_LATITUDE+LOCATION_LONGITUDE+LOCATION_TYPE+
INCIDENT_AREA_TYPE+INCIDENT_AREA_SUBTYPE+SYSTEM_PART_INVOLVED+CAUSE+COMMODITY_RELEASED_TYPE+
COMMODITY_SUBTYPE+UNINTENTIONAL_RELEASE_BBLS+INTENTIONAL_RELEASE_BBLS+RECOVERED_BBLS+
RELEASE_TYPE+IGNITE_IND+EXPLODE_IND+SHUTDOWN_DUE_ACCIDENT_IND+STILL_SHUTDOWN_IND+NUM_PUB_EVACUATED+
INJURY_IND+NUM_EMP_INJURIES+NUM_CONTR_INJURIES+NUM_WORKER_INJURIES+NUM_GP_INJURIES+INJURE+
FATALITY_IND+NUM_EMP_FATALITIES+NUM_CONTR_FATALITIES+NUM_WORKER_FATALITIES+NUM_GP_FATALITIES+
FATAL+WILDLIFE_IMPACT_IND+FISH_AQUATIC_IMPACT_IND+BIRDS_IMPACT_IND+TERRESTRIAL_IMPACT_IND+
SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+
SOIL_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+WATER_CONTAM_IND+OCEAN_SEAWATER_IND+
SURFACE_CONTAM_IND+GROUNDWATER_CONTAM_IND+COMMODITY_REACHED_HCA+EVACUATION+response_delay
,data = trainset, method = 'anova', control = rpart.control(minsplit = 2, cp = 0))
printcp(cart1)
plotcp(cart1)
print(cart1)
#Step 2: Prune Tree to min
##2.1: Find Optimal cp:
#store the cptable
dt<-data.table(cart1$cptable)
#number the sequence of the trees
dt[,index:=1:nrow(dt)]
#find out minimum index where xerror is min
min_cp_index<-min(dt[(xerror+xstd)==min(xerror+xstd),index])
#find the errorcap
errorcap<-dt[min_cp_index,xerror+xstd]
#find out the optimal index for the cp
optimal_cp_index <- min(dt[(xerror < errorcap), index])
#Find the geometric mean of the cp for that index and one cp appearing before it
optimal.cp=sqrt(dt[index==optimal_cp_index,CP]*dt[index==optimal_cp_index-1,CP]) #0.09585533
##2.2: Prune the max tree using optimal.cp
cartOptimal <- prune(cart1, cp = optimal.cp)
printcp(cartOptimal, digits = 3)
print(cartOptimal)
rpart.plot(cartOptimal, nn = T, main = "Optimal Tree in Accident")
cartOptimal$variable.importance
summary(cartOptimal)
# Step 3: Evaluate the CART Model
##3.1: create the evaluation metrics function
eval_CART <- function(true_value, predicted_value, data) {
SSE <- sum((predicted_value - true_value)^2) #Explained Sum of Squares / Sum of Squares Error
SST <- sum((true_value - mean(true_value))^2) #Total Sum of Squares
R_square <- 1 - SSE / SST
RMSE = sqrt(SSE/nrow(data))
# Model performance metrics
data.frame(
RMSE = RMSE,
Rsquare = R_square
)
}
##3.2: predicting and evaluating the model on train data
predictions_train_cart = predict(cartOptimal, data = trainset)
eval_CART(trainset$TOTAL_COST, predictions_train_cart, trainset) #RMSE: 153717.5, Rsquare: 0.4233723
##3.3: predicting and evaluating the model on test data
predictions_test_cart = predict(cartOptimal, newdata = testset)
eval_CART(testset$TOTAL_COST, predictions_test_cart, testset) #RMSE: 167133.9, Rsquare: 0.1558794
#Read in the outputed original dataframe in phase 1 and store it to accident_full
accident_full <- fread("accident_clean.csv")
#Investigate on records with high TOTAL_COST
#function to count the number of outliers
count_outliers <- function(data, column_name) {
quartiles <- quantile(data[[column_name]], na.rm = TRUE, probs = c(0.25, 0.75))
IQR_val <- IQR(data[[column_name]],na.rm=TRUE)
lower_bound <- quartiles[1] - 1.5 * IQR_val #Lower whisker
upper_bound <- quartiles[2] + 1.5 * IQR_val #Upper whisker
outliers_count <- sum(data[[column_name]] < lower_bound | data[[column_name]] > upper_bound, na.rm = TRUE) #IQR Method to identify outliers
return(outliers_count)
}
count_outliers(accident_full,"TOTAL_COST") #566 outliers
# ================================================================
# Data Processing: convert to nominal categorical var
#=================================================================
accident_full$`NAME` <- factor(accident_full$`NAME`)
accident_full$`PIPE_FAC_NAME` <- factor(accident_full$`PIPE_FAC_NAME`)
accident_full$`ON_OFF_SHORE` <- factor(accident_full$`ON_OFF_SHORE`)
accident_full$`ON_OFF_SHORE` <- factor(accident_full$`ON_OFF_SHORE`)
accident_full$`ONSHORE_STATE_ABBREVIATION` <- factor(accident_full$`ONSHORE_STATE_ABBREVIATION`)
accident_full$`ONSHORE_CITY_NAME` <- factor(accident_full$`ONSHORE_CITY_NAME`)
accident_full$`ONSHORE_COUNTY_NAME` <- factor(accident_full$`ONSHORE_COUNTY_NAME`)
accident_full$`LOCATION_TYPE` <- factor(accident_full$`LOCATION_TYPE`)
accident_full$`INCIDENT_AREA_TYPE` <- factor(accident_full$`INCIDENT_AREA_TYPE`)
accident_full$`INCIDENT_AREA_SUBTYPE` <- factor(accident_full$`INCIDENT_AREA_SUBTYPE`)
accident_full$`INCIDENT_AREA_DETAILS` <- factor(accident_full$`INCIDENT_AREA_DETAILS`)
accident_full$`DEPTH_OF_COVER` <- factor(accident_full$`DEPTH_OF_COVER`)
accident_full$`SYSTEM_PART_INVOLVED` <- factor(accident_full$`SYSTEM_PART_INVOLVED`)
accident_full$`CAUSE` <- factor(accident_full$`CAUSE`)
accident_full$`CAUSE_DETAILS` <- factor(accident_full$`CAUSE_DETAILS`)
accident_full$`COMMODITY_RELEASED_TYPE` <- factor(accident_full$`COMMODITY_RELEASED_TYPE`)
accident_full$`COMMODITY_SUBTYPE` <- factor(accident_full$`COMMODITY_SUBTYPE`)
accident_full$`COMMODITY_DETAILS` <- factor(accident_full$`COMMODITY_DETAILS`)
accident_full$`PIPE_DIAMETER` <- factor(accident_full$`PIPE_DIAMETER`)
accident_full$`PIPE_WALL_THICKNESS` <- factor(accident_full$`PIPE_WALL_THICKNESS`)
accident_full$`PIPE_SMYS` <- factor(accident_full$`PIPE_SMYS`)
accident_full$`PIPE_SPECIFICATION` <- factor(accident_full$`PIPE_SPECIFICATION`)
accident_full$`INSTALLATION_YEAR` <- factor(accident_full$`INSTALLATION_YEAR`)
accident_full$`MATERIAL_INVOLVED` <- factor(accident_full$`MATERIAL_INVOLVED`)
accident_full$`MATERIAL_DETAILS` <- factor(accident_full$`MATERIAL_DETAILS`)
accident_full$`RELEASE_TYPE` <- factor(accident_full$`RELEASE_TYPE`)
accident_full$`IGNITE_IND` <- factor(accident_full$`IGNITE_IND`)
accident_full$`EXPLODE_IND` <- factor(accident_full$`EXPLODE_IND`)
accident_full$`SHUTDOWN_DUE_accident_full_IND` <- factor(accident_full$`SHUTDOWN_DUE_accident_full_IND`)
accident_full$`STILL_SHUTDOWN_IND` <- factor(accident_full$`STILL_SHUTDOWN_IND`)
accident_full$`INJURY_IND` <- factor(accident_full$`INJURY_IND`)
accident_full$`FATALITY_IND` <- factor(accident_full$`FATALITY_IND`)
accident_full$`WILDLIFE_IMPACT_IND` <- factor(accident_full$`WILDLIFE_IMPACT_IND`)
accident_full$`FISH_AQUATIC_IMPACT_IND` <- factor(accident_full$`FISH_AQUATIC_IMPACT_IND`)
accident_full$`BIRDS_IMPACT_IND` <- factor(accident_full$`BIRDS_IMPACT_IND`)
accident_full$`TERRESTRIAL_IMPACT_IND` <- factor(accident_full$`TERRESTRIAL_IMPACT_IND`)
accident_full$`SOIL_CONTAMINATION` <- factor(accident_full$`SOIL_CONTAMINATION`)
accident_full$`LONG_TERM_ASSESSMENT` <- factor(accident_full$`LONG_TERM_ASSESSMENT`)
accident_full$`REMEDIATION_IND` <- factor(accident_full$`REMEDIATION_IND`)
accident_full$`SURFACE_WATER_REMED_IND` <- factor(accident_full$`SURFACE_WATER_REMED_IND`)
accident_full$`GROUNDWATER_REMED_IND` <- factor(accident_full$`GROUNDWATER_REMED_IND`)
accident_full$`SOIL_REMED_IND` <- factor(accident_full$`SOIL_REMED_IND`)
accident_full$`VEGETATION_REMED_IND` <- factor(accident_full$`VEGETATION_REMED_IND`)
accident_full$`WILDLIFE_REMED_IND` <- factor(accident_full$`WILDLIFE_REMED_IND`)
accident_full$`WATER_CONTAM_IND` <- factor(accident_full$`WATER_CONTAM_IND`)
accident_full$`OCEAN_SEAWATER_IND` <- factor(accident_full$`OCEAN_SEAWATER_IND`)
accident_full$`SURFACE_CONTAM_IND` <- factor(accident_full$`SURFACE_CONTAM_IND`)
accident_full$`GROUNDWATER_CONTAM_IND` <- factor(accident_full$`GROUNDWATER_CONTAM_IND`)
accident_full$`DRINKING_WATER_CONTAM_IND` <- factor(accident_full$`DRINKING_WATER_CONTAM_IND`)
accident_full$`PRIVATE_WELL_CONTAM_IND` <- factor(accident_full$`PRIVATE_WELL_CONTAM_IND`)
accident_full$`PUBLIC_WATER_CONTAM_IND` <- factor(accident_full$`PUBLIC_WATER_CONTAM_IND`)
accident_full$`EVACUATION` <- factor(accident_full$`EVACUATION`)
#------------------------------------
# In our solution, we define records with TOTAL_COST above the Upper Whisker, i.e., Q3+1.5*IQR, as high cost accident
quartiles <- quantile(accident_full[["TOTAL_COST"]], na.rm = TRUE, probs = c(0.25, 0.75))
IQR_val <- IQR(accident_full[["TOTAL_COST"]],na.rm=TRUE)
upper_bound <- quartiles[2] + 1.5 * IQR_val #Upper whisker for TOTAL_COST
# Create New Categorical Variable, HIGH_COST_ALERT
accident_full[, HIGH_COST_ALERT:=factor(ifelse((TOTAL_COST>=upper_bound),"YES","NO"))] #classify accidents based on their TOTAL_COST
summary(accident_full$HIGH_COST_ALERT)
# ----------------------------------
#Train-Test Split
set.seed(2406)
train <- sample.split(Y = accident_full$HIGH_COST_ALERT, SplitRatio = 0.7)
trainset <- subset(accident_full, train == T)
testset <- subset(accident_full, train == F)
summary(trainset$HIGH_COST_ALERT) #2328 NO, 396 YES
summary(testset$HIGH_COST_ALERT) #997 NO, 170 YES
#Balance the trainset
train.bal<-trainset[order(-HIGH_COST_ALERT),][1:1188,]
#Check trainset is balanced
summary(train.bal$HIGH_COST_ALERT) #792 NO, 396 YES
#Step 1: Fit the Logistic Regression Model using all relevant predictor variables
alert_m <- glm(HIGH_COST_ALERT ~ IYEAR+ON_OFF_SHORE+LOCATION_LATITUDE+LOCATION_LONGITUDE+LOCATION_TYPE+INCIDENT_AREA_TYPE+
INTENTIONAL_RELEASE_BBLS+CAUSE+COMMODITY_RELEASED_TYPE+IGNITE_IND+RECOVERED_BBLS+RELEASE_TYPE+EXPLODE_IND+
SHUTDOWN_DUE_ACCIDENT_IND+NUM_PUB_EVACUATED+INJURY_IND+NUM_EMP_INJURIES+NUM_CONTR_INJURIES+NUM_WORKER_INJURIES+
NUM_GP_INJURIES+INJURE+FATALITY_IND+NUM_EMP_FATALITIES+NUM_CONTR_FATALITIES+NUM_WORKER_FATALITIES+NUM_GP_FATALITIES+
FATAL+WILDLIFE_IMPACT_IND+FISH_AQUATIC_IMPACT_IND+BIRDS_IMPACT_IND+SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+
REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+
WATER_CONTAM_IND+SURFACE_CONTAM_IND+COMMODITY_REACHED_HCA+EVACUATION+UNINTENTIONAL_RELEASE_BBLS+TERRESTRIAL_IMPACT_IND+
SOIL_REMED_IND+OCEAN_SEAWATER_IND+GROUNDWATER_CONTAM_IND+response_delay
,family = binomial, data = train.bal)
summary(alert_m) #Abnormal pattern: p-value for all variables are smaller than the significance level of 0.1%
#Step 2: Find the predictor variable(s) causing complete separation to occur using detect_separation()
library("detectseparation") # https://www.rdocumentation.org/packages/brglm2/versions/0.7.1/topics/detect_separation
m_detect<-glm(HIGH_COST_ALERT ~ IYEAR+ON_OFF_SHORE+LOCATION_LATITUDE+LOCATION_LONGITUDE+LOCATION_TYPE+INCIDENT_AREA_TYPE+
INTENTIONAL_RELEASE_BBLS+CAUSE+COMMODITY_RELEASED_TYPE+IGNITE_IND+RECOVERED_BBLS+RELEASE_TYPE+EXPLODE_IND+
SHUTDOWN_DUE_ACCIDENT_IND+NUM_PUB_EVACUATED+INJURY_IND+NUM_EMP_INJURIES+NUM_CONTR_INJURIES+NUM_WORKER_INJURIES+
NUM_GP_INJURIES+INJURE+FATALITY_IND+NUM_EMP_FATALITIES+NUM_CONTR_FATALITIES+NUM_WORKER_FATALITIES+NUM_GP_FATALITIES+
FATAL+WILDLIFE_IMPACT_IND+FISH_AQUATIC_IMPACT_IND+BIRDS_IMPACT_IND+SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+
REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+WATER_CONTAM_IND+
SURFACE_CONTAM_IND+COMMODITY_REACHED_HCA+EVACUATION+UNINTENTIONAL_RELEASE_BBLS+TERRESTRIAL_IMPACT_IND+SOIL_REMED_IND+
OCEAN_SEAWATER_IND+GROUNDWATER_CONTAM_IND+response_delay
,data=train.bal,family = binomial("logit"),method = "detect_separation")
m_detect
#Remove potential completely separated predictors (i.e., with value Inf or -Inf)
alert_m2 <- glm(HIGH_COST_ALERT ~ IYEAR+LOCATION_LATITUDE+LOCATION_LONGITUDE+ INTENTIONAL_RELEASE_BBLS+CAUSE+IGNITE_IND+
RECOVERED_BBLS+RELEASE_TYPE+SHUTDOWN_DUE_ACCIDENT_IND+INJURY_IND+SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+
REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+
COMMODITY_REACHED_HCA+UNINTENTIONAL_RELEASE_BBLS+SOIL_REMED_IND+response_delay,
family = binomial, data = train.bal)
#Although we still receive the warning, but now the summary shows different p-values for each variable
summary(alert_m2)
#Step 3: Remove statistically less significant predictor variable using backward elimination
#https://www.utstat.toronto.edu/~brunner/oldclass/appliedf11/handouts/2101f11StepwiseLogisticR.pdf
alert_m3 <- step(alert_m2)
summary(alert_m3)
#Step 4: Remove practically irrelevant variables: LOCATION_LATITUDE and LOCATION_LONGITUDE
alert_m4 <- glm(HIGH_COST_ALERT ~ IYEAR+INTENTIONAL_RELEASE_BBLS + CAUSE + IGNITE_IND +
RECOVERED_BBLS + SHUTDOWN_DUE_ACCIDENT_IND + LONG_TERM_ASSESSMENT +
GROUNDWATER_REMED_IND + VEGETATION_REMED_IND + UNINTENTIONAL_RELEASE_BBLS +
response_delay,
family = binomial, data = train.bal)
summary(alert_m4)
OR.alert_m4<- exp(coef(alert_m4))
round(OR.alert_m4, 3)
OR.CI.alert_m4 <- exp(confint(alert_m4))
round(OR.CI.alert_m4,3)
#Step 5: Check VIF Values for multicollinearity
vif(alert_m4) #No multicollinearity
#Step 6: Model Evaluation and Interpretation (https://www.statology.org/logistic-regression-in-r/)
##6.1 Model Fit
# R2 value is not defined for logistic regression. Instead, we can compute a metric known as McFadden’s R2, which ranges from 0 to just under 1.
# Values close to 0 indicate that the model has no predictive power. In practice, values over 0.40 indicate that a model fits the data very well.
pscl::pR2(alert_m4)["McFadden"]
##6.2Variable Importance
caret::varImp(alert_m4)
#Step 7: Model Performance Metrics
# Make predictions on the test data
# Logistic Reg Confusion Matrix on Testset
threshold<-0.5
m.prob <- predict(alert_m4, newdata = testset, type = 'response')
m.predict <- ifelse(m.prob > threshold, "YES", "NO")
# Confusion matrix
table1 <- table(Testset.Actual = testset$HIGH_COST_ALERT, logreg.predict = m.predict, deparse.level = 2)
table1
round(prop.table(table1), 3)
# Overall Accuracy
mean(m.predict == testset$HIGH_COST_ALERT)
# ROC curve and AUC: higher the AUC, the better the model is at predicting (https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)
library(pROC)
roc_obj <- roc(testset$HIGH_COST_ALERT, m.prob)
auc <- auc(roc_obj) #0.66: moderate predictive power
plot(roc_obj, main = paste("AUC =", round(auc, 2)))
set.seed(1) #for 10-fold CV
# Step 1: Grow Tree to max and set cp to 0
alert_CART <- rpart(HIGH_COST_ALERT ~ IYEAR+ON_OFF_SHORE+LOCATION_LATITUDE+LOCATION_LONGITUDE+LOCATION_TYPE+INCIDENT_AREA_TYPE+
INTENTIONAL_RELEASE_BBLS+CAUSE+COMMODITY_RELEASED_TYPE+IGNITE_IND+RECOVERED_BBLS+RELEASE_TYPE+EXPLODE_IND+
SHUTDOWN_DUE_ACCIDENT_IND+NUM_PUB_EVACUATED+INJURY_IND+NUM_EMP_INJURIES+NUM_CONTR_INJURIES+NUM_WORKER_INJURIES+
NUM_GP_INJURIES+INJURE+FATALITY_IND+NUM_EMP_FATALITIES+NUM_CONTR_FATALITIES+NUM_WORKER_FATALITIES+NUM_GP_FATALITIES+
FATAL+WILDLIFE_IMPACT_IND+FISH_AQUATIC_IMPACT_IND+BIRDS_IMPACT_IND+SOIL_CONTAMINATION+LONG_TERM_ASSESSMENT+
REMEDIATION_IND+SURFACE_WATER_REMED_IND+GROUNDWATER_REMED_IND+VEGETATION_REMED_IND+VEGETATION_REMED_IND+WATER_CONTAM_IND+
SURFACE_CONTAM_IND+COMMODITY_REACHED_HCA+EVACUATION+UNINTENTIONAL_RELEASE_BBLS+TERRESTRIAL_IMPACT_IND+SOIL_REMED_IND+
OCEAN_SEAWATER_IND+GROUNDWATER_CONTAM_IND+response_delay,
data = train.bal, method = 'class', control = rpart.control(minsplit = 2, cp = 0))
printcp(alert_CART)
plotcp(alert_CART)
# Step 2: Prune Tree to min
# 2.1: Find Optimal cp:
#store the cptable
dt<-data.table(alert_CART$cptable)
#number the sequence of the trees
dt[,index:=1:nrow(dt)]
#find out minimum index where xerror is min
min_cp_index<-min(dt[(xerror+xstd)==min(xerror+xstd),index])
#find the errorcap
errorcap<-dt[min_cp_index,xerror+xstd]
#find out the optimal index for the cp
optimal_cp_index <- min(dt[(xerror < errorcap), index])
#Find the geometric mean of the cp for that index and one cp appearing before it
cp.opt=sqrt(dt[index==optimal_cp_index,CP]*dt[index==optimal_cp_index-1,CP]) #0.01115121
# 2.2: Prune the max tree using optimal.cp
alert_CART_optimal <- prune(alert_CART, cp = cp.opt)
print(alert_CART_optimal)
rpart.plot(alert_CART_optimal)
summary(alert_CART_optimal)
alert_CART_optimal$variable.importance
# Step 3: Evaluate the CART Model
cart.predict <- predict(alert_CART_optimal, newdata = testset, type = "class")
table2 <- table(Testset.Actual = testset$HIGH_COST_ALERT, cart.predict, deparse.level = 2)
table2
round(prop.table(table2), 3)
# Overall Accuracy
mean(cart.predict == testset$HIGH_COST_ALERT)
